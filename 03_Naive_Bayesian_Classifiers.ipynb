{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/ms_logo.jpeg' height=40% width=40%></center>\n",
    "\n",
    "<center><h1>Naive Bayesian Classifiers</h1></center>\n",
    "\n",
    "In this notebook, we'll be focusing on **_Naive Bayesian Classifiers_**, or \"Naive Bayes\" for short.  This is an algorithm that uses **_Bayes' Theorem_** to make a classification based on probability.  In case you're unfamiliar with Bayes' Theorem, let's look at the formula:\n",
    "<br>\n",
    "<br>\n",
    "<center><img src='img/bayes_theorem.png' height=40% width=40%></center>\n",
    "<br>\n",
    "<br>\n",
    "Don't worry if you've seen this mathematical notation before. In plain English, that formula reads:\n",
    "\n",
    "\"The probability of A given B equals the probability of B given A, times the probability of A, divided by the probability of B\".  \n",
    "\n",
    "Let's run through an example case here and see if we can demystify this equation a little bit more. \n",
    "\n",
    "<center><h3>Scenario: Spam Detection</h3></center>\n",
    "\n",
    "We have a dataset of emails, and we're trying to build a classifier that can predict if an email is spam or not by examining the words based in the emails.  Each email in our training set has been labeled as \"spam\" or \"ham\" (a real email, not spam).  We've counted each word used in every email, and found the following:\n",
    "\n",
    "**_65% of the emails in the dataset are \"Spam\"._**\n",
    "\n",
    "**_\"Spam\"_** emails contain the word _\"deal\"_ 80% of the time, and _\"win\"_ 40% of the time.  \n",
    "\n",
    "**_35% of the emails in the datasert are \"Ham\"._**\n",
    "\n",
    "**_\"Ham\"_** emails contain the word _\"deal\"_ 17% of the time, and _\"win\"_ 6% of the time.  \n",
    "\n",
    "The next email we try to predict contains the both words \"deal\" and \"win\". Given the information above, we can plug these numbers into Bayes' Theorem and predict the likelihood that this is email Spam. \n",
    "\n",
    "<center>P(Spam|deal, win) = (P(win, deal|Spam) * P(Spam)) / P(deal, win)</center>\n",
    "\n",
    "This can be further broken down into: \n",
    "<br>\n",
    "<br>\n",
    "<center>P(Spam|deal) \\* P(Spam|win) = P(deal|Spam) \\* P(Spam) \\*  P(win|Spam) \\* P(Spam) / P(deal|Spam) + P(deal|!Spam) \\* P(win|Spam) + P(win|!Spam)</center>\n",
    "\n",
    "In the equation above, \"P(deal|!Spam)\" can be read as \"the percentage that 'deal' occurs in 'Ham' emails\".  \n",
    "\n",
    "On the next step, we'll start defining the probabilities for everything in that equation so we can plug them in:\n",
    "\n",
    "1. P(deal|Spam) = .8\n",
    "1. P(win|Spam) = .4\n",
    "1. P(Spam) = .65\n",
    "1. P(deal|!Spam) = .17\n",
    "1. P(win|!Spam) = .06\n",
    "1. P(!Spam) = .35\n",
    "\n",
    "Let's replace some of these terms with the probabilities listed above and see how it works out:\n",
    "<br>\n",
    "<br>\n",
    "<center>(.8 \\* .65 \\* .4 \\* .65) / .8 \\* .65 + .35 \\* .17 \\* .4 \\* .65 + .35 \\* .6 = **0.922595** </center>\n",
    "<br>\n",
    "<br>\n",
    "Based on the math from Bayes' Theorem, we can predict probability that a new email containing both \"deal\" and \"win\" is \"Spam\" is approximately **92.2%**!\n",
    "\n",
    "<center><h3>Using Naive Bayes in the Real World</h3></center>\n",
    "\n",
    "In the above example, we did the math by hand.  That isn't very practical in the real world.  Luckily, `sklearn` contains some awesome implementations of Naive Bayesian Classifiers (and regressors!).  \n",
    "\n",
    "For this assignment, we're going to use a `GaussianNB()` object.  There are a few different kinds of Naive Bayesian Classifiers, but for this one we'll stick to one that assumes our data follows a Gaussian (normal) distribution.  \n",
    "\n",
    "Let's Get Started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\n",
      "TEST PREDICTION VECTOR: \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "\n",
      "\n",
      "ACTUAL Y-TEST VALUES: \n",
      "[0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0\n",
      " 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0]\n",
      "\n",
      "\n",
      "CLASSIFICATION REPORT: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       0.94      0.94      0.94        50\n",
      "          2       0.94      0.94      0.94        50\n",
      "\n",
      "avg / total       0.96      0.96      0.96       150\n",
      "\n",
      "\n",
      "\n",
      "CONFUSION MATRIX: \n",
      "[[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(0)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "% matplotlib inline\n",
    "\n",
    "# Uses load_iris() to load data into iris variable, then assigns iris.data and iris.target to appropriate variables\n",
    "iris = load_iris()\n",
    "dataset = iris.data\n",
    "class_label_vector = iris.target\n",
    "\n",
    "# Uses train_test_split to split the data into X_train, X_test, y_train, and y_test variables\n",
    "### X_train, X_test, Y_train, Y_test = train_test_split(dataset, class_label_vector, shuffle=True)\n",
    "\n",
    "# Create a GaussianNB() object and fit it using the training data\n",
    "clf_naïve_bayes = GaussianNB()\n",
    "clf_naïve_bayes.fit(dataset, class_label_vector)\n",
    "print(clf_naïve_bayes)\n",
    "\n",
    "# Uses fitted model to create predictions for X_test data\n",
    "test_prediction_vector = clf_naïve_bayes.predict(dataset)\n",
    "\n",
    "# Gathers and displays classifier resultant information\n",
    "print(\"\\nTEST PREDICTION VECTOR: \\n{}\\n\".format(test_prediction_vector))\n",
    "print(\"\\nACTUAL Y-TEST VALUES: \\n{}\\n\".format(Y_test.ravel()))\n",
    "# print(\"\\nACCURACY SCORE: \\n{}\\n\".format(accuracy_score(test_prediction_vector, Y_test)))\n",
    "# print(\"\\nF1 SCORE: \\n{}\\n\".format(f1_score(Y_test, test_prediction_vector, average=\"weighted\")))\n",
    "print(\"\\nCLASSIFICATION REPORT: \\n{}\\n\".format(classification_report(class_label_vector, test_prediction_vector)))\n",
    "print(\"\\nCONFUSION MATRIX: \\n{}\\n\".format(confusion_matrix(class_label_vector, test_prediction_vector)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Some Caveats</h3></center>\n",
    "\n",
    "You may have wondered why this particular model is a called a **_Naive_** Bayesian Classifier.  In this scenario, the word \"Naive\" simply means that the model makes the \"naive\" assumption that all features are independent of one another.  This leads us to the main caveat of this model--if you have feature columns that are highly correlated, this model may not work as well as we'd like.  **_If you're going to use Naive Bayes, make sure you check for highly correlated features beforehand!_**\n",
    "\n",
    "\n",
    "<center><h3>Where to Go From Here</h3></center>\n",
    "\n",
    "For the latter part of this assignment, you're going to use the famous Pima Indians Diabetes Dataset to build a Naive Bayesian Classifier that predicts whether or not an individual has diabetes.  You'll find the `pima_indians_diabetes.csv` file inside the `datasets` folder.  \n",
    "\n",
    "To build this classifier successfully, you'll want to follow the best practices for loading in and preprocessing a data set that you've learned in class:\n",
    "\n",
    "1. Importing the data\n",
    "1. Exploring the data\n",
    "1. \"Cleaning\" the data\n",
    "1. Splitting the data into training and testing sets (or using KFold Cross val--more on this below)\n",
    "1. Fitting the model\n",
    "1. Validating the model (checking predictions on the test set)\n",
    "\n",
    "Be sure to consider the following questions as you solve this problem:\n",
    "\n",
    "* How will you deal with null values?\n",
    "* For this model, does scaling the data improve your results? (HINT: test your assumption!)\n",
    "\n",
    "On top of cleaning and preprocessing this data set, you'll also use **_Cross Validation_** to get a better measure of the accuracy of your model.  We did not use K Fold Cross Validation in the above model on purpose--instead, you'll need to work your way through `sklearn`'s [model_selection documentation](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) to figure out how to effectively make use of cross-validation.  \n",
    "\n",
    "(**_Hint:_** There are several ways to implement cross validation using sklearn.  In the `model_selection` section of the documentation, pay special attention to the `KFold` object, as well as the methods available under the _Model Selection_ subsection.)\n",
    "\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to file: \"datasets/pima_indians_diabetes.csv\". The first row of the .csv contains the column names.\n",
    "# Note that in the \"Outcome\" column, 0 denotes someone that does NOT have diabetes, and 1 denotes someone that does.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Data\n",
    "PATH = \"./datasets/pima_indians_diabetes.csv\"\n",
    "raw_df = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 45.,  45.,  41.,  35.,  44.,  20.,  21.,  10.,   3.,   4.]),\n",
       " array([ 21. ,  25.9,  30.8,  35.7,  40.6,  45.5,  50.4,  55.3,  60.2,\n",
       "         65.1,  70. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAD8ZJREFUeJzt3X+s3XV9x/HnS6rbRBeoXEhtywqm\nOHGZhTWIYzEoQ4EYq8nYIJsjhqX+ARkwlwX9xx8JCUsUNpONpAITEwQ7hdAYpnYdi3OJaIsdv2q1\nAoNLO1qHApsJW/G9P873rge89J57zz0993x8PpKTc76f8znf7/vTe86r3/v5fs/3pqqQJLXrFeMu\nQJI0Wga9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXHLxl0AwHHHHVdr1qwZdxmS\nNFF27Njxo6qamqvfkgj6NWvWsH379nGXIUkTJcm/D9LPqRtJapxBL0mNM+glqXFzBn2S1UnuSbIr\nyUNJrujaP57kySQ7u9sFfa/5SJI9SXYnefcoByBJOrxBDsYeBD5cVfcleS2wI8nW7rnrq+pT/Z2T\nnApcBLwZeD3wj0lOqaoXFrNwSdJg5tyjr6p9VXVf9/g5YBew8jAv2QDcXlXPV9WjwB7gjMUoVpI0\nf/Oao0+yBjgNuLdrujzJ/UluTnJs17YSeKLvZdPM8h9Dko1JtifZfuDAgXkXLkkazMBBn+Q1wJeB\nK6vqWeAG4A3AOmAf8OmZrrO8/Of+XmFVbaqq9VW1fmpqzvP9JUkLNFDQJ3klvZC/taruAKiqp6rq\nhar6GfBZDk3PTAOr+16+Cti7eCVLkuZjzoOxSQLcBOyqquv62ldU1b5u8f3Ag93jLcAXklxH72Ds\nWuDbi1p1n+u3fn9Uq57TVeeeMrZtS9KgBjnr5izgA8ADSXZ2bR8FLk6yjt60zGPAhwCq6qEkm4GH\n6Z2xc5ln3EjS+MwZ9FX1TWafd7/7MK+5BrhmiLokSYvEb8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXO\noJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6\nSWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJek\nxhn0ktQ4g16SGjdn0CdZneSeJLuSPJTkiq59eZKtSX7Q3R/btSfJZ5LsSXJ/ktNHPQhJ0ssbZI/+\nIPDhqnoTcCZwWZJTgauBbVW1FtjWLQOcD6ztbhuBGxa9aknSwOYM+qraV1X3dY+fA3YBK4ENwC1d\nt1uA93WPNwCfr55vAcckWbHolUuSBjKvOfoka4DTgHuBE6pqH/T+MwCO77qtBJ7oe9l01yZJGoOB\ngz7Ja4AvA1dW1bOH6zpLW82yvo1JtifZfuDAgUHLkCTN00BBn+SV9EL+1qq6o2t+amZKprvf37VP\nA6v7Xr4K2PvSdVbVpqpaX1Xrp6amFlq/JGkOg5x1E+AmYFdVXdf31Bbgku7xJcBdfe1/3J19cybw\nzMwUjyTpyFs2QJ+zgA8ADyTZ2bV9FLgW2JzkUuBx4MLuubuBC4A9wE+BDy5qxZKkeZkz6Kvqm8w+\n7w5wziz9C7hsyLokSYvEb8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Lj\nDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6g\nl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Lj5gz6\nJDcn2Z/kwb62jyd5MsnO7nZB33MfSbInye4k7x5V4ZKkwQyyR/854LxZ2q+vqnXd7W6AJKcCFwFv\n7l7zt0mOWqxiJUnzN2fQV9U3gKcHXN8G4Paqer6qHgX2AGcMUZ8kaUjDzNFfnuT+bmrn2K5tJfBE\nX5/prk2SNCYLDfobgDcA64B9wKe79szSt2ZbQZKNSbYn2X7gwIEFliFJmsuCgr6qnqqqF6rqZ8Bn\nOTQ9Mw2s7uu6Ctj7MuvYVFXrq2r91NTUQsqQJA1gQUGfZEXf4vuBmTNytgAXJfmlJCcBa4FvD1ei\nJGkYy+bqkOQ24GzguCTTwMeAs5Osozct8xjwIYCqeijJZuBh4CBwWVW9MJrSJUmDmDPoq+riWZpv\nOkz/a4BrhilKkrR4/GasJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCX\npMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklq\nnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1bs6gT3Jz\nkv1JHuxrW55ka5IfdPfHdu1J8pkke5Lcn+T0URYvSZrbIHv0nwPOe0nb1cC2qloLbOuWAc4H1na3\njcANi1OmJGmh5gz6qvoG8PRLmjcAt3SPbwHe19f++er5FnBMkhWLVawkaf4WOkd/QlXtA+juj+/a\nVwJP9PWb7tokSWOy2AdjM0tbzdox2Zhke5LtBw4cWOQyJEkzFhr0T81MyXT3+7v2aWB1X79VwN7Z\nVlBVm6pqfVWtn5qaWmAZkqS5LFvg67YAlwDXdvd39bVfnuR24K3AMzNTPC26fuv3x7Ldq849ZSzb\nlTSZ5gz6JLcBZwPHJZkGPkYv4DcnuRR4HLiw6343cAGwB/gp8MER1CxJmoc5g76qLn6Zp86ZpW8B\nlw1blCRp8fjNWElqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+gl\nqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIa\nZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJatyyYV6c5DHgOeAF\n4GBVrU+yHPgisAZ4DPj9qvrxcGVKkhZqMfbo31FV66pqfbd8NbCtqtYC27plSdKYjGLqZgNwS/f4\nFuB9I9iGJGlAwwZ9AV9PsiPJxq7thKraB9DdHz/kNiRJQxhqjh44q6r2Jjke2Jrke4O+sPuPYSPA\niSeeOGQZkqSXM9QefVXt7e73A3cCZwBPJVkB0N3vf5nXbqqq9VW1fmpqapgyJEmHseA9+iRHA6+o\nque6x+8CPglsAS4Bru3u71qMQnXI9Vu/P7ZtX3XuKWPbtqSFGWbq5gTgziQz6/lCVX01yXeAzUku\nBR4HLhy+TEnSQi046KvqEeAts7T/J3DOMEXNx8lPf+NIbWqkHln+9nGXIKlRwx6MlV5s9z+Mfhtv\nPH/025Aa4iUQJKlx7tEvEUdiCmoxpofmOhB88tNPDr2N2WxYt3Ik65V+EbhHL0mNM+glqXEGvSQ1\nzqCXpMZ5MPYXSCvfOZA0P+7RS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS\n4/xmrCbCXTsPXf74kceP7N/M9e/katK5Ry9JjXOPXprFi64LtPuHi78B/xyijiCDXhPHi7NJ8+PU\njSQ1zqCXpMYZ9JLUOOfopSXq+q1H9jTSGZ5O2h736CWpce7RS3qRcf0mAf42MSru0UtS49yjl+bQ\nf/mFRbPzxjm7nDzkJh5Z/vYh16BWuEcvSY0z6CWpcQa9JDXOoJekxo3sYGyS84C/Bo4Cbqyqa0e1\nLUnjsegXmJvtSqFe6XNoIwn6JEcBfwOcC0wD30mypaoeHsX2JP28SbzK52xnOB2JPzTT+vn7o5q6\nOQPYU1WPVNX/ALcDG0a0LUnSYYxq6mYl8ETf8jTw1hFtS5KG0vq3gUcV9JmlrV7UIdkIbOwW/yvJ\n7gHWexzwoyFrWyocy9LUylhaGQc0PpY/G259vzZIp1EF/TSwum95FbC3v0NVbQI2zWelSbZX1frh\nyxs/x7I0tTKWVsYBjmUxjGqO/jvA2iQnJXkVcBGwZUTbkiQdxkj26KvqYJLLga/RO73y5qp6aBTb\nkiQd3sjOo6+qu4G7F3m185rqWeIcy9LUylhaGQc4lqGlqubuJUmaWF4CQZIat2SDPsnqJPck2ZXk\noSRXdO3Lk2xN8oPu/thx1zqXJL+c5NtJ/q0byye69pOS3NuN5YvdgeslL8lRSb6b5Cvd8qSO47Ek\nDyTZmWR71zZx7y+AJMck+VKS73WfmbdN2liSvLH7Wczcnk1y5aSNY0aSq7rP+4NJbutyYCyflSUb\n9MBB4MNV9SbgTOCyJKcCVwPbqmotsK1bXuqeB95ZVW8B1gHnJTkT+Evg+m4sPwYuHWON83EFsKtv\neVLHAfCOqlrXd8rbJL6/oHddqa9W1a8Db6H385mosVTV7u5nsQ74LeCnwJ1M2DgAkqwE/hRYX1W/\nQe+klIsY12elqibiBtxF79o5u4EVXdsKYPe4a5vnOF4N3Efvm8I/ApZ17W8Dvjbu+gaofxW9D9s7\nga/Q+3LcxI2jq/Ux4LiXtE3c+wv4VeBRumNukzyWvtrfBfzrpI6DQ1cHWE7vpJevAO8e12dlKe/R\n/78ka4DTgHuBE6pqH0B3f/z4KhtcN92xE9gPbAV+CPykqg52XabpvTmWur8C/gL4Wbf8OiZzHND7\ntvbXk+zovqkNk/n+Ohk4APxdN6V2Y5KjmcyxzLgIuK17PHHjqKongU8BjwP7gGeAHYzps7Lkgz7J\na4AvA1dW1bPjrmehquqF6v1KuoreRd/eNFu3I1vV/CR5D7C/qnb0N8/SdUmPo89ZVXU6cD69qcFJ\n/SOry4DTgRuq6jTgv5mA6Y2X081bvxf4+3HXslDdcYQNwEnA64Gj6b3PXuqIfFaWdNAneSW9kL+1\nqu7omp9KsqJ7fgW9PeSJUVU/Af6Z3nGHY5LMfJfh5y4TsQSdBbw3yWP0rkj6Tnp7+JM2DgCqam93\nv5/eXPAZTOb7axqYrqp7u+Uv0Qv+SRwL9ALxvqp6qluexHH8LvBoVR2oqv8F7gB+mzF9VpZs0CcJ\ncBOwq6qu63tqC3BJ9/gSenP3S1qSqSTHdI9/hd6bYBdwD/B7XbclP5aq+khVraqqNfR+tf6nqvpD\nJmwcAEmOTvLamcf05oQfZALfX1X1H8ATSd7YNZ0DPMwEjqVzMYembWAyx/E4cGaSV3dZNvMzGctn\nZcl+YSrJ7wD/AjzAofngj9Kbp98MnEjvH/PCqnp6LEUOKMlvArfQO/L+CmBzVX0yycn09oyXA98F\n/qiqnh9fpYNLcjbw51X1nkkcR1fznd3iMuALVXVNktcxYe8vgCTrgBuBVwGPAB+ke68xQWNJ8mp6\nBzFPrqpnurZJ/Zl8AvgDemcQfhf4E3pz8kf8s7Jkg16StDiW7NSNJGlxGPSS1DiDXpIaZ9BLUuMM\neklqnEEvSY0z6CWpcQa9JDXu/wCRii1d7vwFwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2519d6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore the Data\n",
    "\n",
    "column_metadata = {\"Pregnancies\": [\"Number of times pregnant\"], \n",
    "                   \"Glucose\": [\"Plasma glucose concentration a 2 hours in an oral glucose tolerance test\"],\n",
    "                   \"BloodPressure\": [\"Diastolic blood pressure (mmHg)\"],\n",
    "                   \"SkinThickness\": [\"Triceps skin fold thickness (mm)\"],\n",
    "                   \"Insulin\": [\"2-Hour serum insulin (mu U/ml)\"],\n",
    "                   \"BMI\": [\"Body mass index (weight in kg/(height in m)^2)\"],\n",
    "                   \"DiabetesPedigreeFunction\": [\"Diabetes pedigree function\"],\n",
    "                   \"Age\": [\"Age (years)\"],\n",
    "                   \"Outcome\": [\"Class variable (0 or 1)\"]}\n",
    "column_metadata_df = pd.DataFrame.from_dict(column_metadata).T\n",
    "### column_metadata_df\n",
    "\n",
    "# plt.hist(raw_df[\"Age\"], raw_df[\"Outcome\"])\n",
    "non_diabetic_ages = raw_df[raw_df[\"Outcome\"] == 0][\"Age\"]\n",
    "diabetic_ages = raw_df[raw_df[\"Outcome\"] == 1][\"Age\"]\n",
    "plt.hist(non_diabetic_ages, alpha=0.5)    # Blue\n",
    "plt.hist(diabetic_ages, alpha=0.3)        # Orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omit zero-values from: GLUCOSE, BLOODPRESSURE, SKINTHICKNESS, BMI, INSULIN\n",
    "raw_df = raw_df[raw_df[\"Glucose\"] > 0]\n",
    "raw_df = raw_df[raw_df[\"BloodPressure\"] > 0]\n",
    "raw_df = raw_df[raw_df[\"SkinThickness\"] > 0]\n",
    "raw_df = raw_df[raw_df[\"BMI\"] > 0]\n",
    "raw_df = raw_df[raw_df[\"Insulin\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 392 artists>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wcpu3l0Sn3grwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a27b82be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(raw_df[\"Glucose\"], raw_df[\"Outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Clean\" the Data\n",
    "\n",
    "# RANK FOR DATA POTENCY: Glucose --> BMI --> SkinThickness --> Age | Four dimensions to use\n",
    "dropped_df = raw_df.drop(columns=[\"Pregnancies\", \"BloodPressure\", \"Insulin\", \"DiabetesPedigreeFunction\"])\n",
    "cleaned_df = dropped_df[[\"Glucose\", \"BMI\", \"SkinThickness\", \"Age\", \"Outcome\"]]\n",
    "dataset = raw_df.as_matrix(columns=[\"Glucose\", \"BMI\", \"SkinThickness\", \"Age\"])\n",
    "class_label_vector = raw_df.as_matrix(columns=[\"Outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST PREDICTION VECTOR: \n",
      "[1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0\n",
      " 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0]\n",
      "\n",
      "\n",
      "ACTUAL Y-TEST VALUES: \n",
      "[1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0\n",
      " 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0]\n",
      "\n",
      "\n",
      "ACCURACY SCORE: \n",
      "0.8061\n",
      "\n",
      "\n",
      "F1 SCORE: \n",
      "0.8009\n",
      "\n",
      "\n",
      "CLASSIFICATION REPORT: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.90      0.85        62\n",
      "          1       0.79      0.64      0.71        36\n",
      "\n",
      "avg / total       0.80      0.81      0.80        98\n",
      "\n",
      "\n",
      "\n",
      "CONFUSION MATRIX: \n",
      "[[56  6]\n",
      " [13 23]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the Data into Training and Test Sets (or using KFold Cross Validation)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset, class_label_vector, shuffle=True)\n",
    "\n",
    "# Fit the Data\n",
    "naïve_bayes_classifier = GaussianNB()\n",
    "naïve_bayes_classifier.fit(X_train, Y_train.ravel())\n",
    "\n",
    "# Validate the Data Model (Check Predictions on Test Set)\n",
    "test_predictions = naïve_bayes_classifier.predict(X_test)\n",
    "\n",
    "# # Gathers and displays classifier resultant information\n",
    "print(\"\\nTEST PREDICTION VECTOR: \\n{}\\n\".format(test_predictions))\n",
    "print(\"\\nACTUAL Y-TEST VALUES: \\n{}\\n\".format(Y_test.ravel()))\n",
    "print(\"\\nACCURACY SCORE: \\n{0:.4f}\\n\".format(accuracy_score(test_predictions, Y_test)))\n",
    "print(\"\\nF1 SCORE: \\n{0:.4f}\\n\".format(f1_score(Y_test, test_predictions, average=\"weighted\")))\n",
    "print(\"\\nCLASSIFICATION REPORT: \\n{}\\n\".format(classification_report(Y_test, test_predictions)))\n",
    "print(\"\\nCONFUSION MATRIX: \\n{}\\n\".format(confusion_matrix(Y_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST PREDICTION VECTOR: \n",
      "[1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0]\n",
      "\n",
      "\n",
      "ACTUAL Y-TEST VALUES: \n",
      "[1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0]\n",
      "\n",
      "\n",
      "ACCURACY SCORE: \n",
      "0.8462\n",
      "\n",
      "\n",
      "F1 SCORE: \n",
      "0.8426\n",
      "\n",
      "\n",
      "CLASSIFICATION REPORT: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89        52\n",
      "          1       0.82      0.69      0.75        26\n",
      "\n",
      "avg / total       0.84      0.85      0.84        78\n",
      "\n",
      "\n",
      "\n",
      "CONFUSION MATRIX: \n",
      "[[48  4]\n",
      " [ 8 18]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Analysis with K-Folds Cross Validation\n",
    "def construct_kf(num_splits):\n",
    "    return StratifiedKFold(n_splits=num_splits, shuffle=True)\n",
    "\n",
    "kf = construct_kf(5)\n",
    "for train_index, test_index in kf.split(dataset, class_label_vector):\n",
    "    X_train, X_test = dataset[train_index], dataset[test_index]\n",
    "    Y_train, Y_test = class_label_vector[train_index], class_label_vector[test_index]\n",
    "    # print(\"\\nTRAINING DATA: \\n{}\\n\".format(train_index))\n",
    "    # print(\"\\nTEST DATA: \\n{}\\n\".format(test_index))\n",
    "    \n",
    "# Fit the Data\n",
    "naïve_bayes_classifier = GaussianNB()\n",
    "naïve_bayes_classifier.fit(X_train, Y_train.ravel())\n",
    "\n",
    "# Validate the Data Model (Check Predictions on Test Set)\n",
    "test_predictions = naïve_bayes_classifier.predict(X_test)\n",
    "\n",
    "# # Gathers and displays classifier resultant information\n",
    "print(\"\\nTEST PREDICTION VECTOR: \\n{}\\n\".format(test_predictions))\n",
    "print(\"\\nACTUAL Y-TEST VALUES: \\n{}\\n\".format(Y_test.ravel()))\n",
    "print(\"\\nACCURACY SCORE: \\n{0:.4f}\\n\".format(accuracy_score(test_predictions, Y_test)))\n",
    "print(\"\\nF1 SCORE: \\n{0:.4f}\\n\".format(f1_score(Y_test, test_predictions, average=\"weighted\")))\n",
    "print(\"\\nCLASSIFICATION REPORT: \\n{}\\n\".format(classification_report(Y_test, test_predictions)))\n",
    "print(\"\\nCONFUSION MATRIX: \\n{}\\n\".format(confusion_matrix(Y_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
